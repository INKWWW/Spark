{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.basis\n",
    "    1.1 SparkSession--DataFrame&SQL的入口\n",
    "    1.2 DataFrame操作\n",
    "    1.3 SQL的操作\n",
    "    1.4 Estimator, Transformer, and Param\n",
    "2.LR\n",
    "\n",
    "3.GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SparkSession是DataFrame和SQL功能的主入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.master(\"spark://10.0.120.106:7077\").appName(\"spark_app\").config(\"\", \"\").getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local\").appName(\"spark_app\").config(\"\", \"\").getOrCreate()\n",
    "\n",
    "# main entry of programming Spark with DataFrame. 'enableHiveSupport()' enables spark to utilize SQL or HQL\n",
    "# A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files.\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark_app\").config(\"\", \"\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BR-IT-A00803:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22fff57a080>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 读取数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='5.1', _c1='3.5', _c2='1.4', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.9', _c1='3.0', _c2='1.4', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.7', _c1='3.2', _c2='1.3', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.6', _c1='3.1', _c2='1.5', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='5.0', _c1='3.6', _c2='1.4', _c3='0.2', _c4='Iris-setosa')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然是txt格式，但是按照csv来读取可以设置seperator\n",
    "read_data = spark.read.csv('C:\\spark\\data\\my_data\\iris_data.txt', sep=',')\n",
    "read_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = read_data.randomSplit([0.7, 0.3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 操作dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A distributed collection of data grouped into named columns. A DataFrame is equivalent to a relational table in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+\n",
      "|_c0|_c1|_c2|_c3|            _c4|\n",
      "+---+---+---+---+---------------+\n",
      "|4.3|3.0|1.1|0.1|    Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|    Iris-setosa|\n",
      "|4.4|3.0|1.3|0.2|    Iris-setosa|\n",
      "|4.4|3.2|1.3|0.2|    Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|    Iris-setosa|\n",
      "|4.6|3.2|1.4|0.2|    Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|    Iris-setosa|\n",
      "|4.6|3.6|1.0|0.2|    Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|    Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|    Iris-setosa|\n",
      "|4.8|3.0|1.4|0.3|    Iris-setosa|\n",
      "|4.8|3.1|1.6|0.2|    Iris-setosa|\n",
      "|4.8|3.4|1.6|0.2|    Iris-setosa|\n",
      "|4.8|3.4|1.9|0.2|    Iris-setosa|\n",
      "|4.9|2.5|4.5|1.7| Iris-virginica|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|\n",
      "|5.0|2.0|3.5|1.0|Iris-versicolor|\n",
      "|5.0|2.3|3.3|1.0|Iris-versicolor|\n",
      "|5.0|3.2|1.2|0.2|    Iris-setosa|\n",
      "|5.0|3.3|1.4|0.2|    Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|    Iris-setosa|\n",
      "|5.0|3.5|1.3|0.3|    Iris-setosa|\n",
      "|5.0|3.5|1.6|0.6|    Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|    Iris-setosa|\n",
      "|5.1|3.3|1.7|0.5|    Iris-setosa|\n",
      "|5.1|3.4|1.5|0.2|    Iris-setosa|\n",
      "|5.1|3.5|1.4|0.2|    Iris-setosa|\n",
      "|5.1|3.7|1.5|0.4|    Iris-setosa|\n",
      "|5.2|2.7|3.9|1.4|Iris-versicolor|\n",
      "|5.2|4.1|1.5|0.1|    Iris-setosa|\n",
      "|5.3|3.7|1.5|0.2|    Iris-setosa|\n",
      "|5.4|3.0|4.5|1.5|Iris-versicolor|\n",
      "|5.4|3.4|1.5|0.4|    Iris-setosa|\n",
      "|5.4|3.7|1.5|0.2|    Iris-setosa|\n",
      "|5.4|3.9|1.3|0.4|    Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|    Iris-setosa|\n",
      "|5.5|2.4|3.7|1.0|Iris-versicolor|\n",
      "|5.5|2.4|3.8|1.1|Iris-versicolor|\n",
      "|5.5|2.5|4.0|1.3|Iris-versicolor|\n",
      "|5.5|3.5|1.3|0.2|    Iris-setosa|\n",
      "|5.5|4.2|1.4|0.2|    Iris-setosa|\n",
      "|5.6|2.5|3.9|1.1|Iris-versicolor|\n",
      "|5.6|2.8|4.9|2.0| Iris-virginica|\n",
      "|5.6|2.9|3.6|1.3|Iris-versicolor|\n",
      "|5.6|3.0|4.1|1.3|Iris-versicolor|\n",
      "|5.6|3.0|4.5|1.5|Iris-versicolor|\n",
      "|5.7|2.5|5.0|2.0| Iris-virginica|\n",
      "|5.7|2.6|3.5|1.0|Iris-versicolor|\n",
      "|5.7|2.8|4.1|1.3|Iris-versicolor|\n",
      "+---+---+---+---+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the structure of dataframe - [train_data]\n",
    "train_data.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3', '_c4']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all columns' names\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the num of rows\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|5.2|4.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "train_data.filter(train_data._c3=='0.1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(_c3)|\n",
      "+--------+\n",
      "|     2.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.agg({'_c3': 'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         avg(_c3)|\n",
      "+-----------------+\n",
      "|1.161320754716981|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.agg({'_c3': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates or replaces a local temporary view\n",
    "train_data.createOrReplaceTempView('train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.4|3.0|1.3|0.2|Iris-setosa|\n",
      "|4.4|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|4.6|3.2|1.4|0.2|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|4.6|3.6|1.0|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.3|Iris-setosa|\n",
      "|4.8|3.1|1.6|0.2|Iris-setosa|\n",
      "|4.8|3.4|1.6|0.2|Iris-setosa|\n",
      "|4.8|3.4|1.9|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|5.0|3.2|1.2|0.2|Iris-setosa|\n",
      "|5.0|3.3|1.4|0.2|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.5|1.3|0.3|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_1 = spark.sql(\"select * from train_table where _c4=='Iris-setosa'\")\n",
    "train_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|               _c0|                _c1|               _c2|               _c3|           _c4|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               106|                106|               106|               106|           106|\n",
      "|   mean| 5.770754716981132|  3.071698113207549|3.6443396226415086| 1.161320754716981|          null|\n",
      "| stddev|0.7997579373228328|0.44588162362012673|1.7494532581939912|0.7643946568198022|          null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe the dataframe by providing basic statistics for numeric and string columns\n",
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|_c0|\n",
      "+---+\n",
      "|4.3|\n",
      "|4.4|\n",
      "|4.4|\n",
      "|4.4|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.7|\n",
      "|4.8|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select('_c0').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.7'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.2'),\n",
       " Row(_c0='5.2'),\n",
       " Row(_c0='5.3'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.9'),\n",
       " Row(_c0='5.9'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.2'),\n",
       " Row(_c0='6.2'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.6'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.9'),\n",
       " Row(_c0='7.0'),\n",
       " Row(_c0='7.1'),\n",
       " Row(_c0='7.2'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.9')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='4.3')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').take(5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').take(5)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 操作column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'_c0'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data._c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'_c0'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['_c0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b2840de4e87d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_c0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "# show the result - 'column' object is not callable\n",
    "train_data['_c0'].collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do calculations on dataframe through column\n",
    "\n",
    "operate_data = train_data.select(['_c0', '_c1'])\n",
    "operate_data\n",
    "# operate_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(_c0 + _c1)'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "add_col = operate_data._c0 + operate_data['_c1']\n",
    "add_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_operate_data = operate_data.withColumn('sum', add_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------------+\n",
      "|_c0|_c1|               sum|\n",
      "+---+---+------------------+\n",
      "|4.3|3.0|               7.3|\n",
      "|4.4|2.9| 7.300000000000001|\n",
      "|4.4|3.0|               7.4|\n",
      "|4.4|3.2|7.6000000000000005|\n",
      "|4.6|3.1| 7.699999999999999|\n",
      "+---+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_operate_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Row(value='5.1,3.5,1.4,0.2,Iris-setosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='5.1,3.5,1.4,0.2,Iris-setosa')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
