{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.classification import LogisticRegressionSummary\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "# from pyspark.sql.functions import when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.basis\n",
    "\n",
    "2.LR\n",
    "\n",
    "3.GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator:\n",
    "An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. \n",
    "E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n",
    "\n",
    "Transformer:\n",
    "A Transformer is an algorithm which can transform one DataFrame into another DataFrame. \n",
    "E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SparkSession是DataFrame和SQL功能的主入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.master(\"spark://10.0.120.106:7077\").appName(\"spark_app\").config(\"\", \"\").getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local\").appName(\"spark_app\").config(\"\", \"\").getOrCreate()\n",
    "\n",
    "# main entry of programming Spark with DataFrame. 'enableHiveSupport()' enables spark to utilize SQL or HQL\n",
    "# A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files.\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark_app\").config(\"\", \"\").enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BR-IT-A00803:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d82726bb00>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 读取数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='5.1', _c1='3.5', _c2='1.4', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.9', _c1='3.0', _c2='1.4', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.7', _c1='3.2', _c2='1.3', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='4.6', _c1='3.1', _c2='1.5', _c3='0.2', _c4='Iris-setosa'),\n",
       " Row(_c0='5.0', _c1='3.6', _c2='1.4', _c3='0.2', _c4='Iris-setosa')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然是txt格式，但是按照csv来读取可以设置seperator\n",
    "read_data = spark.read.csv('C:\\spark\\data\\my_data\\iris_data.txt', sep=',')\n",
    "read_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读写hive\n",
    "# df = spark.sql('select * from xxx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = read_data.randomSplit([0.7, 0.3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 操作dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A distributed collection of data grouped into named columns. A DataFrame is equivalent to a relational table in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+\n",
      "|_c0|_c1|_c2|_c3|            _c4|\n",
      "+---+---+---+---+---------------+\n",
      "|4.3|3.0|1.1|0.1|    Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|    Iris-setosa|\n",
      "|4.4|3.0|1.3|0.2|    Iris-setosa|\n",
      "|4.4|3.2|1.3|0.2|    Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|    Iris-setosa|\n",
      "|4.6|3.2|1.4|0.2|    Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|    Iris-setosa|\n",
      "|4.6|3.6|1.0|0.2|    Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|    Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|    Iris-setosa|\n",
      "|4.8|3.0|1.4|0.3|    Iris-setosa|\n",
      "|4.8|3.1|1.6|0.2|    Iris-setosa|\n",
      "|4.8|3.4|1.6|0.2|    Iris-setosa|\n",
      "|4.8|3.4|1.9|0.2|    Iris-setosa|\n",
      "|4.9|2.5|4.5|1.7| Iris-virginica|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|\n",
      "|5.0|2.0|3.5|1.0|Iris-versicolor|\n",
      "|5.0|2.3|3.3|1.0|Iris-versicolor|\n",
      "|5.0|3.2|1.2|0.2|    Iris-setosa|\n",
      "|5.0|3.3|1.4|0.2|    Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|    Iris-setosa|\n",
      "|5.0|3.5|1.3|0.3|    Iris-setosa|\n",
      "|5.0|3.5|1.6|0.6|    Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|    Iris-setosa|\n",
      "|5.1|3.3|1.7|0.5|    Iris-setosa|\n",
      "|5.1|3.4|1.5|0.2|    Iris-setosa|\n",
      "|5.1|3.5|1.4|0.2|    Iris-setosa|\n",
      "|5.1|3.7|1.5|0.4|    Iris-setosa|\n",
      "|5.2|2.7|3.9|1.4|Iris-versicolor|\n",
      "|5.2|4.1|1.5|0.1|    Iris-setosa|\n",
      "|5.3|3.7|1.5|0.2|    Iris-setosa|\n",
      "|5.4|3.0|4.5|1.5|Iris-versicolor|\n",
      "|5.4|3.4|1.5|0.4|    Iris-setosa|\n",
      "|5.4|3.7|1.5|0.2|    Iris-setosa|\n",
      "|5.4|3.9|1.3|0.4|    Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|    Iris-setosa|\n",
      "|5.5|2.4|3.7|1.0|Iris-versicolor|\n",
      "|5.5|2.4|3.8|1.1|Iris-versicolor|\n",
      "|5.5|2.5|4.0|1.3|Iris-versicolor|\n",
      "|5.5|3.5|1.3|0.2|    Iris-setosa|\n",
      "|5.5|4.2|1.4|0.2|    Iris-setosa|\n",
      "|5.6|2.5|3.9|1.1|Iris-versicolor|\n",
      "|5.6|2.8|4.9|2.0| Iris-virginica|\n",
      "|5.6|2.9|3.6|1.3|Iris-versicolor|\n",
      "|5.6|3.0|4.1|1.3|Iris-versicolor|\n",
      "|5.6|3.0|4.5|1.5|Iris-versicolor|\n",
      "|5.7|2.5|5.0|2.0| Iris-virginica|\n",
      "|5.7|2.6|3.5|1.0|Iris-versicolor|\n",
      "|5.7|2.8|4.1|1.3|Iris-versicolor|\n",
      "+---+---+---+---+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the structure of dataframe - [train_data]\n",
    "train_data.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3', '_c4']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all columns' names\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the num of rows\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|5.2|4.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "train_data.filter(train_data._c3=='0.1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+--------------+\n",
      "|_c0|_c1|_c2|_c3|           _c4|\n",
      "+---+---+---+---+--------------+\n",
      "|4.9|2.5|4.5|1.7|Iris-virginica|\n",
      "|5.6|2.8|4.9|2.0|Iris-virginica|\n",
      "|5.7|2.5|5.0|2.0|Iris-virginica|\n",
      "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
      "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
      "+---+---+---+---+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# contains\n",
    "train_data.filter(train_data._c4.contains('virginica')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(_c3)|\n",
      "+--------+\n",
      "|     2.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The available aggregate functions are avg, max, min, sum, count.\n",
    "train_data.agg({'_c3': 'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         avg(_c3)|\n",
      "+-----------------+\n",
      "|1.161320754716981|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.agg({'_c3': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          sum(_c3)|\n",
      "+------------------+\n",
      "|123.09999999999998|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.agg({'_c3': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates or replaces a local temporary view\n",
    "train_data.createOrReplaceTempView('train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.4|3.0|1.3|0.2|Iris-setosa|\n",
      "|4.4|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|4.6|3.2|1.4|0.2|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|4.6|3.6|1.0|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.3|Iris-setosa|\n",
      "|4.8|3.1|1.6|0.2|Iris-setosa|\n",
      "|4.8|3.4|1.6|0.2|Iris-setosa|\n",
      "|4.8|3.4|1.9|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|5.0|3.2|1.2|0.2|Iris-setosa|\n",
      "|5.0|3.3|1.4|0.2|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.5|1.3|0.3|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query like sql\n",
    "train_1 = spark.sql(\"select * from train_table where _c4=='Iris-setosa'\")\n",
    "train_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|               _c0|                _c1|               _c2|               _c3|           _c4|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               106|                106|               106|               106|           106|\n",
      "|   mean| 5.770754716981132|  3.071698113207549|3.6443396226415086| 1.161320754716981|          null|\n",
      "| stddev|0.7997579373228328|0.44588162362012673|1.7494532581939912|0.7643946568198022|          null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe the dataframe by providing basic statistics for numeric and string columns\n",
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|               _c0|                _c1|               _c2|               _c3|           _c4|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               106|                106|               106|               106|           106|\n",
      "|   mean| 5.770754716981132|  3.071698113207549|3.6443396226415086| 1.161320754716981|          null|\n",
      "| stddev|0.7997579373228328|0.44588162362012673|1.7494532581939912|0.7643946568198022|          null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    25%|               5.1|                2.8|               1.5|               0.3|          null|\n",
      "|    50%|               5.7|                3.0|               4.1|               1.3|          null|\n",
      "|    75%|               6.3|                3.4|               5.1|               1.8|          null|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add some quartiles statistics infomation\n",
    "train_data.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              _c0|\n",
      "+-------+-----------------+\n",
      "|   mean|5.770754716981132|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summary for specific column and statistics\n",
    "train_data.select('_c0').summary('mean').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|_c0|\n",
      "+---+\n",
      "|4.3|\n",
      "|4.4|\n",
      "|4.4|\n",
      "|4.4|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.6|\n",
      "|4.7|\n",
      "|4.8|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select('_c0').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.6'),\n",
       " Row(_c0='4.7'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.8'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='4.9'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.0'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.1'),\n",
       " Row(_c0='5.2'),\n",
       " Row(_c0='5.2'),\n",
       " Row(_c0='5.3'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.4'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.5'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.6'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.7'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.8'),\n",
       " Row(_c0='5.9'),\n",
       " Row(_c0='5.9'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.0'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.1'),\n",
       " Row(_c0='6.2'),\n",
       " Row(_c0='6.2'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.3'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.4'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.5'),\n",
       " Row(_c0='6.6'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.7'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.8'),\n",
       " Row(_c0='6.9'),\n",
       " Row(_c0='7.0'),\n",
       " Row(_c0='7.1'),\n",
       " Row(_c0='7.2'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.7'),\n",
       " Row(_c0='7.9')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='4.3'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.4'),\n",
       " Row(_c0='4.6')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='4.3')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').take(5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('_c0').take(5)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.select('_c0').take(5)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 操作column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'_c0'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a column in a dataframe\n",
    "train_data._c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'_c0'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['_c0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-70cb9fc2571f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# show the result - 'column' object is not callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_c0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "# show the result - 'column' object is not callable\n",
    "train_data['_c0'].collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|_c0|_c1|\n",
      "+---+---+\n",
      "|4.3|3.0|\n",
      "|4.4|2.9|\n",
      "|4.4|3.0|\n",
      "|4.4|3.2|\n",
      "|4.6|3.1|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do calculations on dataframe through column\n",
    "operate_data = train_data.select(['_c0', '_c1'])\n",
    "operate_data\n",
    "operate_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(_c0 + _c1)'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "add_col = operate_data._c0 + operate_data['_c1']\n",
    "add_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_operate_data = operate_data.withColumn('sum', add_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------------+\n",
      "|_c0|_c1|               sum|\n",
      "+---+---+------------------+\n",
      "|4.3|3.0|               7.3|\n",
      "|4.4|2.9| 7.300000000000001|\n",
      "|4.4|3.0|               7.4|\n",
      "|4.4|3.2|7.6000000000000005|\n",
      "|4.6|3.1| 7.699999999999999|\n",
      "+---+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_operate_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.4|3.0|1.3|0.2|Iris-setosa|\n",
      "|4.4|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|4.6|3.2|1.4|0.2|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|4.6|3.6|1.0|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+------------+\n",
      "|_c0|_c1|_c2|_c3|            _c4|indexedLabel|\n",
      "+---+---+---+---+---------------+------------+\n",
      "|4.3|3.0|1.1|0.1|    Iris-setosa|         0.0|\n",
      "|4.4|2.9|1.4|0.2|    Iris-setosa|         0.0|\n",
      "|4.4|3.0|1.3|0.2|    Iris-setosa|         0.0|\n",
      "|4.4|3.2|1.3|0.2|    Iris-setosa|         0.0|\n",
      "|4.6|3.1|1.5|0.2|    Iris-setosa|         0.0|\n",
      "|4.6|3.2|1.4|0.2|    Iris-setosa|         0.0|\n",
      "|4.6|3.4|1.4|0.3|    Iris-setosa|         0.0|\n",
      "|4.6|3.6|1.0|0.2|    Iris-setosa|         0.0|\n",
      "|4.7|3.2|1.3|0.2|    Iris-setosa|         0.0|\n",
      "|4.8|3.0|1.4|0.1|    Iris-setosa|         0.0|\n",
      "|4.8|3.0|1.4|0.3|    Iris-setosa|         0.0|\n",
      "|4.8|3.1|1.6|0.2|    Iris-setosa|         0.0|\n",
      "|4.8|3.4|1.6|0.2|    Iris-setosa|         0.0|\n",
      "|4.8|3.4|1.9|0.2|    Iris-setosa|         0.0|\n",
      "|4.9|2.5|4.5|1.7| Iris-virginica|         2.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|         0.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|         0.0|\n",
      "|5.0|2.0|3.5|1.0|Iris-versicolor|         1.0|\n",
      "|5.0|2.3|3.3|1.0|Iris-versicolor|         1.0|\n",
      "|5.0|3.2|1.2|0.2|    Iris-setosa|         0.0|\n",
      "+---+---+---+---+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol='_c4', outputCol='indexedLabel')\n",
    "stringIndexer_model = stringIndexer.fit(train_data)\n",
    "train_data_2 = stringIndexer_model.transform(train_data)\n",
    "train_data_2.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Iris-setosa', 0.0), ('Iris-versicolor', 1.0), ('Iris-virginica', 2.0)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the maps relation\n",
    "sorted( set([(i[0], i[1]) for i in train_data_2.select(['_c4', 'indexedLabel']).collect()]), key=lambda x:x[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform string to double\n",
    "train_data = train_data.withColumn('_c0', train_data['_c0'].cast('double'))\\\n",
    "       .withColumn('_c1', train_data['_c1'].cast('double'))\\\n",
    "       .withColumn('_c2', train_data['_c2'].cast('double'))\\\n",
    "       .withColumn('_c3', train_data['_c3'].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### pipeline #####\n",
    "# assemble features to vector and indicate the label\n",
    "input_col = ['_c0', '_c1', '_c2', '_c3']\n",
    "vecAssembler = VectorAssembler(inputCols=input_col, outputCol=\"features\")\n",
    "# new_train_data = vecAssembler.transform(train_data)\n",
    "stringIndexer = StringIndexer(inputCol=\"_c4\", outputCol=\"label\")\n",
    "pipeline = Pipeline(stages=[vecAssembler, stringIndexer])\n",
    "pipelineFit = pipeline.fit(train_data)\n",
    "new_train_data = pipelineFit.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "|_c0|_c1|_c2|_c3|            _c4|         features|label|\n",
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "|4.3|3.0|1.1|0.1|    Iris-setosa|[4.3,3.0,1.1,0.1]|  0.0|\n",
      "|4.4|2.9|1.4|0.2|    Iris-setosa|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|4.4|3.0|1.3|0.2|    Iris-setosa|[4.4,3.0,1.3,0.2]|  0.0|\n",
      "|4.4|3.2|1.3|0.2|    Iris-setosa|[4.4,3.2,1.3,0.2]|  0.0|\n",
      "|4.6|3.1|1.5|0.2|    Iris-setosa|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|4.6|3.2|1.4|0.2|    Iris-setosa|[4.6,3.2,1.4,0.2]|  0.0|\n",
      "|4.6|3.4|1.4|0.3|    Iris-setosa|[4.6,3.4,1.4,0.3]|  0.0|\n",
      "|4.6|3.6|1.0|0.2|    Iris-setosa|[4.6,3.6,1.0,0.2]|  0.0|\n",
      "|4.7|3.2|1.3|0.2|    Iris-setosa|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|4.8|3.0|1.4|0.1|    Iris-setosa|[4.8,3.0,1.4,0.1]|  0.0|\n",
      "|4.8|3.0|1.4|0.3|    Iris-setosa|[4.8,3.0,1.4,0.3]|  0.0|\n",
      "|4.8|3.1|1.6|0.2|    Iris-setosa|[4.8,3.1,1.6,0.2]|  0.0|\n",
      "|4.8|3.4|1.6|0.2|    Iris-setosa|[4.8,3.4,1.6,0.2]|  0.0|\n",
      "|4.8|3.4|1.9|0.2|    Iris-setosa|[4.8,3.4,1.9,0.2]|  0.0|\n",
      "|4.9|2.5|4.5|1.7| Iris-virginica|[4.9,2.5,4.5,1.7]|  2.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "|5.0|2.0|3.5|1.0|Iris-versicolor|[5.0,2.0,3.5,1.0]|  1.0|\n",
      "|5.0|2.3|3.3|1.0|Iris-versicolor|[5.0,2.3,3.3,1.0]|  1.0|\n",
      "|5.0|3.2|1.2|0.2|    Iris-setosa|[5.0,3.2,1.2,0.2]|  0.0|\n",
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_train_data.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3, 3. , 1.1, 0.1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.select('features').collect()[0][0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test_data using pipeline\n",
    "test_data = test_data.withColumn('_c0', test_data['_c0'].cast('double'))\\\n",
    "       .withColumn('_c1', test_data['_c1'].cast('double'))\\\n",
    "       .withColumn('_c2', test_data['_c2'].cast('double'))\\\n",
    "       .withColumn('_c3', test_data['_c3'].cast('double'))\n",
    "\n",
    "new_test_data = pipelineFit.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "|_c0|_c1|_c2|_c3|            _c4|         features|label|\n",
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "|4.5|2.3|1.3|0.3|    Iris-setosa|[4.5,2.3,1.3,0.3]|  0.0|\n",
      "|4.7|3.2|1.6|0.2|    Iris-setosa|[4.7,3.2,1.6,0.2]|  0.0|\n",
      "|4.9|2.4|3.3|1.0|Iris-versicolor|[4.9,2.4,3.3,1.0]|  1.0|\n",
      "|4.9|3.0|1.4|0.2|    Iris-setosa|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "+---+---+---+---+---------------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class pyspark.ml.classification.LogisticRegression(featuresCol='features', labelCol='label', predictionCol='prediction', \n",
    "maxIter=100, regParam=0.0, elasticNetParam=0.0, tol=1e-06, fitIntercept=True, threshold=0.5, thresholds=None,probabilityCol='probability', \n",
    "rawPredictionCol='rawPrediction', standardization=True, weightCol=None, aggregationDepth=2, family='auto', \n",
    "lowerBoundsOnCoefficients=None, upperBoundsOnCoefficients=None, lowerBoundsOnIntercepts=None, upperBoundsOnIntercepts=None)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_48f48c85243b437dced4"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default -> pick 'features' and 'label' columns and input them into the LR model \n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.7)\n",
    "lr_model = lr.fit(new_train_data)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = lr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "1.0963514880151817\n",
      "1.0893542842612507\n",
      "1.054540991144702\n",
      "1.0124314678821982\n",
      "1.011233434646947\n",
      "1.0074285594594459\n",
      "1.0063296684786371\n",
      "1.0055798406732783\n",
      "1.0049471652881403\n",
      "1.00441485771545\n",
      "1.0039481425760803\n"
     ]
    }
   ],
   "source": [
    "# display the objective per iteration\n",
    "objectiveHistory = model_summary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionTrainingSummary' object has no attribute 'areaUnderROC'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-a48c51aef008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# model_summary.roc.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"areaUnderROC: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mareaUnderROC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegressionTrainingSummary' object has no attribute 'areaUnderROC'"
     ]
    }
   ],
   "source": [
    "# model_summary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(model_summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 0.972972972972973\n",
      "label 2: 0.96875\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(model_summary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lr_model.transform(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---------------+-----------------+-----+--------------------+--------------------+----------+\n",
      "|_c0|_c1|_c2|_c3|            _c4|         features|label|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+---------------+-----------------+-----+--------------------+--------------------+----------+\n",
      "|4.5|2.3|1.3|0.3|    Iris-setosa|[4.5,2.3,1.3,0.3]|  0.0|[0.51142041330757...|[0.45890183847011...|       0.0|\n",
      "|4.7|3.2|1.6|0.2|    Iris-setosa|[4.7,3.2,1.6,0.2]|  0.0|[0.82159784030878...|[0.53931700965076...|       0.0|\n",
      "|4.9|2.4|3.3|1.0|Iris-versicolor|[4.9,2.4,3.3,1.0]|  1.0|[-0.1832910414978...|[0.28741978716886...|       1.0|\n",
      "|4.9|3.0|1.4|0.2|    Iris-setosa|[4.9,3.0,1.4,0.2]|  0.0|[0.79189146637344...|[0.53163063661657...|       0.0|\n",
      "|4.9|3.1|1.5|0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|  0.0|[0.84604516243186...|[0.54689505137992...|       0.0|\n",
      "|5.0|3.0|1.6|0.2|    Iris-setosa|[5.0,3.0,1.6,0.2]|  0.0|[0.74615872130630...|[0.52022869947128...|       0.0|\n",
      "|5.0|3.4|1.6|0.4|    Iris-setosa|[5.0,3.4,1.6,0.4]|  0.0|[0.81843594112977...|[0.53546653730066...|       0.0|\n",
      "|5.1|2.5|3.0|1.1|Iris-versicolor|[5.1,2.5,3.0,1.1]|  1.0|[-0.1162728734866...|[0.29995228520471...|       1.0|\n",
      "|5.1|3.5|1.4|0.3|    Iris-setosa|[5.1,3.5,1.4,0.3]|  0.0|[0.94118875478890...|[0.56764454003049...|       0.0|\n",
      "|5.1|3.8|1.5|0.3|    Iris-setosa|[5.1,3.8,1.5,0.3]|  0.0|[1.03148106075906...|[0.59009069948141...|       0.0|\n",
      "+---+---+---+---+---------------+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.5114, 0.0809, -0.1254])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rawPrediction may vary between algorithms, but it intuitively gives a measure of confidence in each possible label (where larger = more confident).\n",
    "prediction.select('rawPrediction').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.4589, 0.2984, 0.2427])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.select('probability').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_summary = prediction.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.summary of DataFrame[_c0: double, _c1: double, _c2: double, _c3: double, _c4: string, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
